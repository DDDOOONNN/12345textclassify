import torch
from transformers import BertTokenizer, BertForSequenceClassification
import json
import os

def load_model(model_path):
    """åŠ è½½æ¨¡å‹å’Œtokenizer"""
    print(f'ğŸ“‚ Loading model from: {model_path}')
    
    # åŠ è½½label encoder
    label_encoder_path = os.path.join(model_path, 'label_encoder.json')
    with open(label_encoder_path, 'r', encoding='utf-8') as f:
        label_info = json.load(f)
    
    class_names = label_info['classes']
    
    # åŠ è½½æ¨¡å‹å’Œtokenizer
    tokenizer = BertTokenizer.from_pretrained(model_path)
    model = BertForSequenceClassification.from_pretrained(model_path)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.eval()
    
    print(f'âœ… Model loaded! Device: {device}\n')
    
    return model, tokenizer, class_names, device

def predict_top5(text, model, tokenizer, class_names, device, max_length=128):
    """é¢„æµ‹å¹¶è¿”å›Top-5ç»“æœ"""
    
    # Tokenize
    encoding = tokenizer(
        text,
        add_special_tokens=True,
        max_length=max_length,
        padding='max_length',
        truncation=True,
        return_attention_mask=True,
        return_tensors='pt'
    )
    
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)
    
    # é¢„æµ‹
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=1)[0]  # è·å–æ¦‚ç‡
    
    # è·å–Top-5
    top5_probs, top5_indices = torch.topk(probs, k=min(5, len(class_names)))
    
    # æ„å»ºç»“æœ
    results = []
    for i in range(len(top5_probs)):
        results.append({
            'rank': i + 1,
            'class': class_names[top5_indices[i]],
            'probability': float(top5_probs[i]),
            'percentage': float(top5_probs[i]) * 100
        })
    
    return results

def print_top5_results(text, results):
    """ç¾è§‚åœ°æ‰“å°Top-5ç»“æœ"""
    print('='*80)
    print('ğŸ“ INPUT TEXT:')
    print('='*80)
    print(f'{text}\n')
    
    print('='*80)
    print('ğŸ† TOP-5 PREDICTIONS:')
    print('='*80)
    
    for result in results:
        rank = result['rank']
        class_name = result['class']
        prob = result['probability']
        percent = result['percentage']
        
        # ç”Ÿæˆè¿›åº¦æ¡
        bar_length = int(prob * 50)
        bar = 'â–ˆ' * bar_length + 'â–‘' * (50 - bar_length)
        
        # æ·»åŠ å¥–ç‰Œemoji
        medal = ['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰', '4ï¸âƒ£', '5ï¸âƒ£'][rank - 1]
        
        print(f'{medal} Rank {rank}: {class_name:<20} {percent:6.2f}% {bar} ({prob:.4f})')
    
    print('='*80 + '\n')

def interactive_mode(model, tokenizer, class_names, device):
    """äº¤äº’å¼æµ‹è¯•æ¨¡å¼"""
    print('\n' + '='*80)
    print('ğŸ® INTERACTIVE TOP-5 PREDICTION MODE')
    print('='*80)
    print('Enter text to see Top-5 predictions (type "quit" or "exit" to stop)\n')
    
    while True:
        text = input('ğŸ“ Input text: ').strip()
        
        if text.lower() in ['quit', 'exit', 'q']:
            print('ğŸ‘‹ Goodbye!')
            break
        
        if not text:
            print('âš ï¸  Empty text, please try again.\n')
            continue
        
        results = predict_top5(text, model, tokenizer, class_names, device)
        print_top5_results(text, results)

def main():
    # ==================== é…ç½® ====================
    MODEL_PATH = '/data/gtm/textclassify/models3/roberta_classifier/checkpoint-epoch-4'
    
    # æ¨¡å¼é€‰æ‹©: 'single' æˆ– 'interactive'
    MODE = 'single'  # æ”¹ä¸º 'single' å¯ä»¥æµ‹è¯•å•æ¡æ–‡æœ¬
    
    # å•æ¡æ–‡æœ¬æµ‹è¯•ï¼ˆä»…åœ¨MODE='single'æ—¶ä½¿ç”¨ï¼‰
    TEST_TEXT = "æ½®å·å¸‚æ¹˜æ¡¥åŒºç¤¾ä¼šä¿é™©åŸºé‡‘ç®¡ç†å±€åœ¨æ ¸æŸ¥å¤±ä¸šä¿é™©å¾…é‡æ—¶ï¼Œå‘ç°ä¸€ä½äººå‘˜åœ¨æ½®å·å’Œå¦é—¨æ€æ˜åŒºåŒæ—¶å‚ä¿å¤±ä¸šä¿é™©ï¼Œéœ€åæŸ¥æ ¸å®ï¼Œè¦æ±‚æä¾›å¦é—¨æ€æ˜åŒºå¤±ä¸šä¿é™©ç§‘çš„å…·ä½“è”ç³»æ–¹å¼åŠåœ°å€ã€‚"
    
    # ==================== åŠ è½½æ¨¡å‹ ====================
    model, tokenizer, class_names, device = load_model(MODEL_PATH)
    
    print(f'ğŸ“Š Total classes: {len(class_names)}')
    print(f'ğŸ“‹ Classes: {", ".join(class_names[:10])}{"..." if len(class_names) > 10 else ""}\n')
    
    # ==================== æ‰§è¡Œé¢„æµ‹ ====================
    if MODE == 'single':
        # å•æ¡æ–‡æœ¬æµ‹è¯•
        results = predict_top5(TEST_TEXT, model, tokenizer, class_names, device)
        print_top5_results(TEST_TEXT, results)
        
    elif MODE == 'interactive':
        # äº¤äº’å¼æ¨¡å¼
        interactive_mode(model, tokenizer, class_names, device)
    
    else:
        print(f'âŒ Unknown mode: {MODE}')
        print('   Available modes: single, interactive')

if __name__ == '__main__':
    main()